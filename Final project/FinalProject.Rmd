---
title: "Project"
author: "Yawen Han"
date: "4/8/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r load}
library(DT)
library(data.table)
set.seed(1)
dat <- fread(input = "WA_Fn-UseC_-Telco-Customer-Churn.csv", verbose = FALSE)
```

## EDA

```{r data_summary}
# change the class of columns from char to factor
changeCols <- colnames(dat)[which(as.vector(dat[,lapply(.SD, class)]) == "character")]
dat[,(changeCols):= lapply(.SD, as.factor), .SDcols = changeCols]
# get the summary of each column
summary(dat)
```

Finding:
1. senior citizen should be factors with binary class instead of numeric class
2. missing values in TotalCharge

```{r senior_citizen}
# convert SeniorCitizen as a binary class with two levels 'yes' and 'no'
dat[,SeniorCitizen:=factor(SeniorCitizen, levels=c(0,1), labels=c("No", "Yes"))]
# check the class of SeniorCitizen
summary(dat[,.(SeniorCitizen)])
```


```{r handle_missing_value}
# check missing values
sapply(dat,function(x)sum(is.na(x)))
# delete missing records
# omit rows where 'x' has a missing value
dat <- na.omit(dat, cols="TotalCharges")
```

```{r distribution}
library(ggplot2)

myplots <- list()  
m<-1
# get column names
col.name<-colnames(dat)
 # plot the bar chart for all columns grouped by Churn
for(i in 2:ncol(dat)){
  name<-paste0("p",m)
  
    # bar chart for categorical variables
  if (dat[,class(get(col.name[i]))] == "factor"){
    myplots[[m]]<-eval(substitute(ggplot(dat, aes(dat[,get(col.name[i])],fill=Churn))+geom_bar(position='dodge')+labs(title = col.name[i])+xlab("")+theme(axis.text.x=element_text(angle=30,hjust=1)),list(i = i)))
  }else{
   # histogram for continuous variables
    myplots[[m]]<-eval(substitute(ggplot(dat, aes(dat[,get(col.name[i])],fill=Churn))+geom_histogram(alpha=0.8,bins=20)+labs(title = col.name[i])+xlab("")+theme(axis.text.x=element_text(angle=30,hjust=1)),list(i = i)))
  }
  m <- m+1
}

```

```{r distribution, fig.height=30}
library(cowplot)
plot_grid(plotlist = myplots, nrow = 10, ncol = 2)
```
```{r correlation, warning=FALSE}
library(corrplot)
# encoding all factor columns as numeric values
factor.col.name<-col.name[dat[,lapply(X=.SD,FUN="class")]=='factor']
dat_encoded<-dat
dat_encoded<-dat_encoded[,eval(factor.col.name):=lapply(X=.SD,FUN=function(x){as.numeric(x)-1}),.SD=factor.col.name]
# correlation plots
corrplot(cor(dat_encoded[2:21]),method='square', type="lower",diag=F,tl.col = "black",tl.cex = 0.8,tl.srt=10)
#Eliminate gender, phoneservice, InternetServie
```

```{r train_test_split}

indexes <- sample(1:nrow(dat), size=0.3*nrow(dat))
test <- dat[indexes,]
train <- dat[-indexes,]
dim(dat)
dim(test)
dim(train)
```
```{r gradient_boosting}
library(gbm)
model <- gbm(Churn ~ ., data=train[,2:21], distribution="multinomial", cv.folds=5) 
# Predicting on test set
predTest <- predict(model, newdata=test[,2:20], n.trees=100, type = "response")
predTest <- setDT(as.data.frame(predTest))
predTest <- predTest[, colnames(.SD)[max.col(.SD, ties.method = "first")]]
predTest <- sub(".100","",x=predTest)# remove pattern
# Checking classification accuracy
accuracy <- mean(predTest == test[,Churn]) 
accuracy
```

```{r random_forest}
library(randomForest)
model <- randomForest(formula = Churn~. , data=train[,2:21],importance=TRUE)
# Predicting on Validation set
predTest <- predict(model, test[,2:20], type = "response")
# Checking classification accuracy
accuracy <- mean(predTest == test[,Churn]) 
accuracy
```

```{r}
importance(model)
```



